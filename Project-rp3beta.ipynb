{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "\n",
    "from scipy.sparse import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data_manager.split_functions.split_train_validation_random_holdout import split_train_in_two_percentage_global_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "urm_path = './content/data_train.csv'\n",
    "urm_all_df = pd.read_csv(filepath_or_buffer=urm_path,\n",
    "                                sep=\",\",\n",
    "                                header=0,\n",
    "                                dtype={0:int, 1:int, 2:float},\n",
    "                                engine='python')\n",
    "\n",
    "urm_all_df.columns = [\"UserID\", \"ItemID\", \"Interaction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "userID_unique = urm_all_df[\"UserID\"].unique()\n",
    "itemID_unique = urm_all_df[\"ItemID\"].unique()\n",
    "\n",
    "n_users = len(userID_unique)\n",
    "n_items = len(itemID_unique)\n",
    "n_interactions = len(urm_all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<13025x22348 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 478730 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urm_all = sps.coo_matrix((urm_all_df[\"Interaction\"].values,\n",
    "                          (urm_all_df[\"UserID\"].values, urm_all_df[\"ItemID\"].values)))\n",
    "\n",
    "urm_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "URM_all = urm_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Split the data and create the evaluator objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'int3232'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Programmazione\\RecSys\\Challenge\\RecSys_Course_AT_PoliMi\\Project-rp3beta.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Programmazione/RecSys/Challenge/RecSys_Course_AT_PoliMi/Project-rp3beta.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mEvaluation\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mEvaluator\u001b[39;00m \u001b[39mimport\u001b[39;00m EvaluatorHoldout\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Programmazione/RecSys/Challenge/RecSys_Course_AT_PoliMi/Project-rp3beta.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m URM_train_validation, URM_test \u001b[39m=\u001b[39m split_train_in_two_percentage_global_sample(URM_all, train_percentage \u001b[39m=\u001b[39m \u001b[39m0.8\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Programmazione/RecSys/Challenge/RecSys_Course_AT_PoliMi/Project-rp3beta.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m URM_train, URM_validation \u001b[39m=\u001b[39m split_train_in_two_percentage_global_sample(URM_train_validation, train_percentage \u001b[39m=\u001b[39m \u001b[39m0.8\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Programmazione/RecSys/Challenge/RecSys_Course_AT_PoliMi/Project-rp3beta.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m evaluator_validation \u001b[39m=\u001b[39m EvaluatorHoldout(URM_validation, cutoff_list\u001b[39m=\u001b[39m[\u001b[39m10\u001b[39m])\n",
      "File \u001b[1;32md:\\Programmazione\\RecSys\\Challenge\\RecSys_Course_AT_PoliMi\\Data_manager\\split_functions\\split_train_validation_random_holdout.py:113\u001b[0m, in \u001b[0;36msplit_train_in_two_percentage_global_sample\u001b[1;34m(URM_all, train_percentage)\u001b[0m\n\u001b[0;32m    108\u001b[0m URM_validation_builder \u001b[39m=\u001b[39m IncrementalSparseMatrix(n_rows\u001b[39m=\u001b[39mnum_users, n_cols\u001b[39m=\u001b[39mnum_items, auto_create_col_mapper\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, auto_create_row_mapper\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    111\u001b[0m URM_train \u001b[39m=\u001b[39m sps\u001b[39m.\u001b[39mcoo_matrix(URM_all)\n\u001b[1;32m--> 113\u001b[0m indices_for_sampling \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39m0\u001b[39m, URM_all\u001b[39m.\u001b[39mnnz, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint3232)\n\u001b[0;32m    114\u001b[0m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mshuffle(indices_for_sampling)\n\u001b[0;32m    116\u001b[0m n_train_interactions \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(URM_all\u001b[39m.\u001b[39mnnz \u001b[39m*\u001b[39m train_percentage)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\numpy\\__init__.py:320\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtesting\u001b[39;00m \u001b[39mimport\u001b[39;00m Tester\n\u001b[0;32m    318\u001b[0m     \u001b[39mreturn\u001b[39;00m Tester\n\u001b[1;32m--> 320\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mmodule \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m has no attribute \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m__name__\u001b[39m, attr))\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'int3232'"
     ]
    }
   ],
   "source": [
    "from Evaluation.Evaluator import EvaluatorHoldout\n",
    "\n",
    "URM_train_validation, URM_test = split_train_in_two_percentage_global_sample(URM_all, train_percentage = 0.8)\n",
    "URM_train, URM_validation = split_train_in_two_percentage_global_sample(URM_train_validation, train_percentage = 0.8)\n",
    "\n",
    "evaluator_validation = EvaluatorHoldout(URM_validation, cutoff_list=[10])\n",
    "evaluator_test = EvaluatorHoldout(URM_test, cutoff_list=[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define hyperparameter set for the desired model, in this case rp3beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Real, Integer, Categorical\n",
    "\n",
    "hyperparameters_range_dictionary = {\n",
    "    \"topK\": Integer(5, 1000),\n",
    "    \"similarity\": Categorical([\"cosine\"]),\n",
    "    \"alpha\": Real(0, 50),\n",
    "    \"beta\": Real(0, 50),\n",
    "    \"min_rating\": Real(0, 0.5),\n",
    "    \"normalize\": Categorical([True, False]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create SearchBayesianSkopt object, providing the desired recommender class and evaluator objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow is not available\n"
     ]
    }
   ],
   "source": [
    "from Recommenders.GraphBased.RP3betaRecommender import RP3betaRecommender\n",
    "from HyperparameterTuning.SearchBayesianSkopt import SearchBayesianSkopt\n",
    "\n",
    "recommender_class = RP3betaRecommender\n",
    "\n",
    "hyperparameterSearch = SearchBayesianSkopt(recommender_class,\n",
    "                                         evaluator_validation=evaluator_validation,\n",
    "                                         evaluator_test=evaluator_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Provide the data needed to create an instance of the model, one trained only on URM_train, the other on URM_train_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HyperparameterTuning.SearchAbstractClass import SearchInputRecommenderArgs\n",
    "  \n",
    "recommender_input_args = SearchInputRecommenderArgs(\n",
    "    CONSTRUCTOR_POSITIONAL_ARGS = [URM_train],     # For a CBF model simply put [URM_train, ICM_train]\n",
    "    CONSTRUCTOR_KEYWORD_ARGS = {},\n",
    "    FIT_POSITIONAL_ARGS = [],\n",
    "    FIT_KEYWORD_ARGS = {},\n",
    "    EARLYSTOPPING_KEYWORD_ARGS = {},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender_input_args_last_test = SearchInputRecommenderArgs(\n",
    "    CONSTRUCTOR_POSITIONAL_ARGS = [URM_train_validation],     # For a CBF model simply put [URM_train_validation, ICM_train]\n",
    "    CONSTRUCTOR_KEYWORD_ARGS = {},\n",
    "    FIT_POSITIONAL_ARGS = [],\n",
    "    FIT_KEYWORD_ARGS = {},\n",
    "    EARLYSTOPPING_KEYWORD_ARGS = {},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Create a result folder and select the number of cases (50 with 30% random is a good number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_folder_path = \"result_experiments/\"\n",
    "\n",
    "# If directory does not exist, create\n",
    "if not os.path.exists(output_folder_path):\n",
    "    os.makedirs(output_folder_path)\n",
    "    \n",
    "n_cases = 10  # using 10 as an example\n",
    "n_random_starts = int(n_cases*0.3)\n",
    "metric_to_optimize = \"MAP\"   \n",
    "cutoff_to_optimize = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameterSearch.search(recommender_input_args,\n",
    "                       recommender_input_args_last_test = recommender_input_args_last_test,\n",
    "                       hyperparameter_search_space = hyperparameters_range_dictionary,\n",
    "                       n_cases = n_cases,\n",
    "                       n_random_starts = n_random_starts,\n",
    "                       save_model = \"last\",\n",
    "                       output_folder_path = output_folder_path, # Where to save the results\n",
    "                       output_file_name_root = recommender_class.RECOMMENDER_NAME, # How to call the files\n",
    "                       metric_to_optimize = metric_to_optimize,\n",
    "                       cutoff_to_optimize = cutoff_to_optimize,\n",
    "                      )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
